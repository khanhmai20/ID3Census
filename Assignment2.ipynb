{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3 on Census Data Ananlysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Day   Outlook Temperature Humidity    Wind PlayTennis\n",
      "0    D1     Sunny         Hot     High    Weak         No\n",
      "1    D2     Sunny         Hot     High  Strong         No\n",
      "2    D3  Overcast         Hot     High    Weak        Yes\n",
      "3    D4      Rain        Mild     High    Weak        Yes\n",
      "4    D5      Rain        Cool   Normal    Weak        Yes\n",
      "5    D6      Rain        Cool   Normal  Strong         No\n",
      "6    D7  Overcast        Cool   Normal  Strong        Yes\n",
      "7    D8     Sunny        Mild     High    Weak         No\n",
      "8    D9     Sunny        Cool   Normal    Weak        Yes\n",
      "9   D10      Rain        Mild   Normal    Weak        Yes\n",
      "10  D11     Sunny        Mild   Normal  Strong        Yes\n",
      "11  D12  Overcast        Mild     High  Strong        Yes\n",
      "12  D13  Overcast         Hot   Normal    Weak        Yes\n",
      "13  D14      Rain        Mild     High  Strong         No \n",
      "\n",
      "     ID  SUSPICIOUS WORDS  UNKNOWN SENDER  CONTAINS IMAGES CLASS\n",
      "0  376              True           False             True  spam\n",
      "1  489              True            True            False  spam\n",
      "2  541              True            True            False  spam\n",
      "3  693             False            True             True   ham\n",
      "4  782             False           False            False   ham\n",
      "5  976             False           False            False   ham\n"
     ]
    }
   ],
   "source": [
    "emails_df = pd.read_csv(\"assets/emails.csv\")\n",
    "playtennis_df = pd.read_csv(\"assets/playtennis.csv\")\n",
    "print(playtennis_df,\"\\n\\n\",emails_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre: dataset as dataFrame object\n",
    "#post: return the entropy from any dataFrame\n",
    "def entropy(dataset):\n",
    "    #Get the classification attribute of this dataset\n",
    "    classifier = dataset.columns[-1]\n",
    "    \n",
    "    #Construct the dictionary to count the occurences of each unique outcome\n",
    "    occurence = {}\n",
    "    for outcome in list(dataset[classifier]):\n",
    "        if outcome not in occurence:\n",
    "            occurence[outcome] = 1\n",
    "        else:\n",
    "            occurence[outcome] += 1\n",
    "    \n",
    "    #Calculate entropy\n",
    "    entropy = 0\n",
    "    for value in occurence.values():\n",
    "        total_outcome = len(dataset[classifier]) #Get the possible outcome of this classification\n",
    "        probability = value/total_outcome\n",
    "        entropy -= probability*math.log2(probability)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Info Gain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre: dataset as dataFrame object\n",
    "#post: return the info gain of all attributes\n",
    "def infoGain(dataset,attribute):\n",
    "    #Construct the dictionary to count the occurences of each unique value attribute\n",
    "    occurence = {}\n",
    "    for value in list(dataset[attribute]):\n",
    "        if value not in occurence:\n",
    "            occurence[value] = 1\n",
    "        else: \n",
    "            occurence[value] += 1\n",
    "    \n",
    "    entropy_Attribute = 0\n",
    "    \n",
    "    #For each unique value, calculate the entropy of the classifier \n",
    "    for value in occurence: \n",
    "        sub_df = dataset[dataset[attribute] == value]\n",
    "        sub_entropy = entropy(sub_df)\n",
    "        probability = occurence[value]/len(dataset[attribute])\n",
    "        entropy_Attribute += probability*sub_entropy\n",
    "        \n",
    "    #We have the following formular\n",
    "    infoGain = entropy(dataset) - entropy_Attribute\n",
    "    \n",
    "    return infoGain   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing infoGain on Playtennis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre: take dataset as parameter\n",
    "#post: return the maximun infoGain attribute\n",
    "\n",
    "def gainfulAttr(dataset):\n",
    "    attributes = list(dataset.columns)[0:-1] #Exclue the classifier attribute\n",
    "    gain_attributes = {} #Key: Attribute, Value: InfoGain\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        if attribute not in gain_attributes:\n",
    "            gain_attributes[attribute] = infoGain(dataset,attribute)\n",
    "    \n",
    "    decision = max(gain_attributes,key=gain_attributes.get)\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Outlook'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gainfulAttr(playtennis_df.drop(columns=['Day']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building ID3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the ID3 model \n",
    "def id3Model(dataset,pruning,dictionary=None):\n",
    "    \n",
    "    #Threshold of penalize dataset when it reach this\n",
    "    #return the most common classes.\n",
    "    if len(dataset) < pruning:\n",
    "        classifiers = list(dataset[dataset.columns[-1]].values)\n",
    "        most_common = max(set(classifiers),key = classifiers.count)\n",
    "        return most_common\n",
    "    \n",
    "    if dictionary is None: \n",
    "        dictionary ={}\n",
    "        \n",
    "    #If this is a pure set, all classes are the same, return the class value\n",
    "    if (len(dataset[dataset.columns[-1]].unique())==1): #pure set\n",
    "        return dataset[dataset.columns[-1]].unique()[0]\n",
    "    \n",
    "    #if no more attribute left\n",
    "    #return the most common classes\n",
    "    if (len(dataset.columns)==1): \n",
    "        classifiers = list(dataset[dataset.columns[-1]].values)\n",
    "        most_common = max(set(classifiers),key = classifiers.count)\n",
    "        return most_common\n",
    "    \n",
    "    #Recurse to build the tree\n",
    "    else:\n",
    "        #start with most gainful attribute attach it to the root node\n",
    "        decision_Attr = gainfulAttr(dataset)\n",
    "        dictionary[decision_Attr] = {} \n",
    "        unique_value = dataset[decision_Attr].unique()\n",
    "        \n",
    "        #iterate values in that attribute\n",
    "        for value in list(unique_value):\n",
    "            \n",
    "            #partition the dataset\n",
    "            sub_dataset = dataset[dataset[decision_Attr]==value]\n",
    "            sub_dataset = sub_dataset.drop(columns=[decision_Attr])\n",
    "            \n",
    "            dictionary[decision_Attr][value] = id3Model(sub_dataset,pruning)\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize ID3 on PlayTennis and Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SUSPICIOUS WORDS': {False: 'ham', True: 'spam'}}\n",
      "\n",
      "\n",
      "{'Outlook': {'Overcast': 'Yes',\n",
      "             'Rain': {'Wind': {'Strong': 'No', 'Weak': 'Yes'}},\n",
      "             'Sunny': {'Humidity': {'High': 'No', 'Normal': 'Yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "emailModel = id3Model(emails_df.drop(columns=['ID']),0)\n",
    "playtennisModel = id3Model(playtennis_df.drop(columns=['Day']),0)\n",
    "\n",
    "census_df = pd.read_csv(\"assets/census_training.csv\")\n",
    "censusModel = id3Model(census_df,0)\n",
    "pprint.pprint(emailModel)\n",
    "print('\\n')\n",
    "pprint.pprint(playtennisModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_test_df = pd.read_csv(\"assets/census_training_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build this Prediction on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre: id3 model, and the query of testing set. query = {attribute1: value1, attribute2: value2,...,}\n",
    "#post: return the prediction of id3 output base on the query\n",
    "def prediction(id3,query,default=1): \n",
    "    \n",
    "    for key in list(query.keys()): \n",
    "        if key in list(id3.keys()):\n",
    "            \n",
    "            try:\n",
    "                result = id3[key][query[key]] \n",
    "            except:\n",
    "                return default \n",
    "            \n",
    "            result = id3[key][query[key]]\n",
    "            if isinstance(result,dict):\n",
    "                return prediction(result,query)\n",
    "            else:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre : input dataset and the example ith\n",
    "#post: building queries \n",
    "\n",
    "def queries(dataset,example): \n",
    "    query = {}\n",
    "    for key in list(dataset.iloc[example][:].keys()):\n",
    "        if key not in query: \n",
    "            query[key] = dataset.iloc[example].get(key)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre : input id3 model and testing data\n",
    "#post: testing the predictions on the dataset, output the statistics\n",
    "def accuracy(id3,testing_data):\n",
    "    correct = 0; \n",
    "    incorrect = 0; \n",
    "    classifier = testing_data.columns[-1]\n",
    "    \n",
    "    for example in range(0,len(testing_data)):\n",
    "        query = queries(testing_data,example)\n",
    "        \n",
    "        predict = prediction(id3,query)\n",
    "        if(query[classifier]==predict):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    \n",
    "    print(\"Number of testing examples =\\t\",len(testing_data))\n",
    "    print(\"Correct classifications =\\t\",correct)\n",
    "    print(\"Incorrect classifications =\\t\",incorrect)\n",
    "    print(\"Accuracy =\\t\\t \",correct/len(testing_data)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with no tree pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing examples =\t 15028\n",
      "Correct classifications =\t 11289\n",
      "Incorrect classifications =\t 3739\n",
      "Accuracy =\t\t  75.11977641735427 %\n"
     ]
    }
   ],
   "source": [
    "accuracy(censusModel,census_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with tree pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing examples =\t 15028\n",
      "Correct classifications =\t 11976\n",
      "Incorrect classifications =\t 3052\n",
      "Accuracy =\t\t  79.69124301304232 %\n"
     ]
    }
   ],
   "source": [
    "censusModel_pruning = id3Model(census_df,30)\n",
    "accuracy(censusModel_pruning,census_test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
